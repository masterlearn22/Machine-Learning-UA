{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat dataset...\n",
      "TF-IDF selesai.\n",
      "Shape X_train_vec: (25000, 4000)\n",
      "Shape X_test_vec : (2000, 4000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from collections import Counter           \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "print(\"Memuat dataset...\")\n",
    "\n",
    "train_df = pd.read_csv(\"../dataset/train.csv\")\n",
    "test_df  = pd.read_csv(\"../dataset/test.csv\")\n",
    "\n",
    "train_df.columns = [\"Class Index\", \"Title\", \"Description\"]\n",
    "test_df.columns  = [\"Class Index\", \"Title\", \"Description\"]\n",
    "\n",
    "train_df[\"text\"] = train_df[\"Title\"] + \" \" + train_df[\"Description\"]\n",
    "test_df[\"text\"]  = test_df[\"Title\"]  + \" \" + test_df[\"Description\"]\n",
    "\n",
    "# Sampling\n",
    "train_df = train_df.sample(25000, random_state=42)\n",
    "test_df  = test_df.sample(2000, random_state=42)\n",
    "\n",
    "X_train_raw = train_df[\"text\"].values\n",
    "X_test_raw  = test_df[\"text\"].values\n",
    "y_train_raw = train_df[\"Class Index\"].values - 1\n",
    "y_test_raw  = test_df[\"Class Index\"].values - 1\n",
    "\n",
    "# TF-IDF \n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=4000,\n",
    "    stop_words=\"english\",\n",
    "    ngram_range=(1,2)\n",
    ")\n",
    "X_train_vec = vectorizer.fit_transform(X_train_raw).toarray()\n",
    "X_test_vec  = vectorizer.transform(X_test_raw).toarray()\n",
    "\n",
    "print(\"TF-IDF selesai.\")\n",
    "print(\"Shape X_train_vec:\", X_train_vec.shape)\n",
    "print(\"Shape X_test_vec :\", X_test_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d260f2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value train:\n",
      " Class Index    0\n",
      "Title          0\n",
      "Description    0\n",
      "text           0\n",
      "dtype: int64\n",
      "\n",
      "Missing value test:\n",
      " Class Index    0\n",
      "Title          0\n",
      "Description    0\n",
      "text           0\n",
      "dtype: int64\n",
      "\n",
      "Setelah drop missing:\n",
      "Train: (25000, 4)\n",
      "Test : (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "# MISSING VALUE\n",
    "print(\"Missing value train:\\n\", train_df.isnull().sum())\n",
    "print(\"\\nMissing value test:\\n\", test_df.isnull().sum())\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df  = test_df.dropna()\n",
    "\n",
    "print(\"\\nSetelah drop missing:\")\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Test :\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b0ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformasi MinMaxScaler selesai.\n",
      "Range: 0.0 → 1.0\n",
      "Shape train: (25000, 4000)\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMASI MINMAX SCALER\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train_vec)\n",
    "X_test_sc  = scaler.transform(X_test_vec)\n",
    "\n",
    "print(\"Transformasi MinMaxScaler selesai.\")\n",
    "print(\"Range:\", X_train_sc.min(), \"→\", X_train_sc.max())\n",
    "print(\"Shape train:\", X_train_sc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "109c57f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sebelum SMOTE (Data Training) ---\n",
      "Jumlah sampel X_train: 25000\n",
      "Distribusi Kelas y_train: Counter({np.int64(3): 6329, np.int64(1): 6303, np.int64(0): 6215, np.int64(2): 6153})\n",
      "\n",
      "--- Setelah SMOTE (Data Training) ---\n",
      "Jumlah sampel X_train_smote: 25316\n",
      "Distribusi Kelas y_train_smote: Counter({np.int64(2): 6329, np.int64(1): 6329, np.int64(3): 6329, np.int64(0): 6329})\n"
     ]
    }
   ],
   "source": [
    "# 3. IMPLEMENTASI SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "print(\"\\n--- Sebelum SMOTE (Data Training) ---\")\n",
    "print(f\"Jumlah sampel X_train: {X_train_sc.shape[0]}\")\n",
    "print(f\"Distribusi Kelas y_train: {Counter(y_train_raw)}\")\n",
    "\n",
    "X_train_smote, y_train_smote = smote.fit_resample(\n",
    "    X_train_sc, y_train_raw\n",
    ")\n",
    "\n",
    "print(\"\\n--- Setelah SMOTE (Data Training) ---\")\n",
    "print(f\"Jumlah sampel X_train_smote: {X_train_smote.shape[0]}\")\n",
    "print(f\"Distribusi Kelas y_train_smote: {Counter(y_train_smote)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "817742ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 44ms/step - accuracy: 0.8400 - loss: 0.4811\n",
      "Epoch 2/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.9189 - loss: 0.2474\n",
      "Epoch 3/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.9326 - loss: 0.1989\n",
      "Epoch 4/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.9425 - loss: 0.1636\n",
      "Epoch 5/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 44ms/step - accuracy: 0.9510 - loss: 0.1343\n",
      "Epoch 6/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.9562 - loss: 0.1143\n",
      "Epoch 7/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 47ms/step - accuracy: 0.9613 - loss: 0.0982\n",
      "Epoch 8/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 44ms/step - accuracy: 0.9667 - loss: 0.0863\n",
      "Epoch 9/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.9725 - loss: 0.0719\n",
      "Epoch 10/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 64ms/step - accuracy: 0.9762 - loss: 0.0610\n",
      "Epoch 11/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.9809 - loss: 0.0494\n",
      "Epoch 12/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.9842 - loss: 0.0433\n",
      "Epoch 13/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 36ms/step - accuracy: 0.9864 - loss: 0.0375\n",
      "Epoch 14/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.9860 - loss: 0.0377\n",
      "Epoch 15/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.9884 - loss: 0.0315\n",
      "Epoch 16/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.9904 - loss: 0.0257\n",
      "Epoch 17/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step - accuracy: 0.9914 - loss: 0.0252\n",
      "Epoch 18/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9930 - loss: 0.0212\n",
      "Epoch 19/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.9935 - loss: 0.0188\n",
      "Epoch 20/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 47ms/step - accuracy: 0.9944 - loss: 0.0169\n",
      "Epoch 21/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.9943 - loss: 0.0167\n",
      "Epoch 22/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 41ms/step - accuracy: 0.9949 - loss: 0.0144\n",
      "Epoch 23/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 44ms/step - accuracy: 0.9952 - loss: 0.0144\n",
      "Epoch 24/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 45ms/step - accuracy: 0.9955 - loss: 0.0127\n",
      "Epoch 25/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.9955 - loss: 0.0139\n",
      "Epoch 26/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.9967 - loss: 0.0106\n",
      "Epoch 27/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.9960 - loss: 0.0115\n",
      "Epoch 28/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9974 - loss: 0.0080\n",
      "Epoch 29/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9977 - loss: 0.0076\n",
      "Epoch 30/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9973 - loss: 0.0086\n",
      "Epoch 31/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 43ms/step - accuracy: 0.9978 - loss: 0.0070\n",
      "Epoch 32/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.9977 - loss: 0.0075\n",
      "Epoch 33/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.9976 - loss: 0.0071\n",
      "Epoch 34/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 37ms/step - accuracy: 0.9974 - loss: 0.0085\n",
      "Epoch 35/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9974 - loss: 0.0077\n",
      "Epoch 36/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 40ms/step - accuracy: 0.9976 - loss: 0.0082\n",
      "Epoch 37/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9981 - loss: 0.0059\n",
      "Epoch 38/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 38ms/step - accuracy: 0.9987 - loss: 0.0045\n",
      "Epoch 39/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 40ms/step - accuracy: 0.9986 - loss: 0.0036\n",
      "Epoch 40/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 37ms/step - accuracy: 0.9984 - loss: 0.0060\n",
      "Epoch 41/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.9987 - loss: 0.0042\n",
      "Epoch 42/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 39ms/step - accuracy: 0.9986 - loss: 0.0044\n",
      "Epoch 43/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9984 - loss: 0.0055\n",
      "Epoch 44/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9985 - loss: 0.0037\n",
      "Epoch 45/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9982 - loss: 0.0052\n",
      "Epoch 46/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9986 - loss: 0.0049\n",
      "Epoch 47/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 37ms/step - accuracy: 0.9986 - loss: 0.0039\n",
      "Epoch 48/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9987 - loss: 0.0040\n",
      "Epoch 49/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 38ms/step - accuracy: 0.9990 - loss: 0.0023\n",
      "Epoch 50/50\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 35ms/step - accuracy: 0.9986 - loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "\n",
    "# LSTM butuh reshape: (samples, time_step, features)\n",
    "X_train_lstm = X_train_sc.reshape((X_train_sc.shape[0], 1, X_train_sc.shape[1]))\n",
    "X_test_lstm  = X_test_sc.reshape((X_test_sc.shape[0], 1, X_test_sc.shape[1]))\n",
    "y_train_cat  = to_categorical(y_train_raw, 4)\n",
    "\n",
    "def build_lstm(shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=shape))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"softmax\"))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Training model LSTM...\")\n",
    "\n",
    "model_lstm = build_lstm((1, X_train_lstm.shape[2]))\n",
    "\n",
    "start = time.time()\n",
    "history = model_lstm.fit(\n",
    "    X_train_lstm,\n",
    "    y_train_cat,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "train_time = time.time() - start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a362ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\n",
      "=== EVALUASI PROSES 4 ===\n",
      "Akurasi : 0.871\n",
      "Presisi : 0.8710797376726673\n",
      "Recall  : 0.871\n",
      "AUC/ROC : 0.9706378625115468\n",
      "Waktu training : 1664.164442539215\n",
      "Waktu testing  : 0.6033868789672852\n"
     ]
    }
   ],
   "source": [
    "# EVALUASI \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "start_test = time.time()\n",
    "y_prob = model_lstm.predict(X_test_lstm)\n",
    "test_time = time.time() - start_test\n",
    "\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test_raw, y_pred)\n",
    "prec = precision_score(y_test_raw, y_pred, average=\"weighted\", zero_division=0)\n",
    "rec = recall_score(y_test_raw, y_pred, average=\"weighted\", zero_division=0)\n",
    "auc = roc_auc_score(to_categorical(y_test_raw, 4), y_prob, multi_class=\"ovr\")\n",
    "\n",
    "print(\"\\n=== EVALUASI PROSES 4 ===\")\n",
    "print(\"Akurasi :\", acc)\n",
    "print(\"Presisi :\", prec)\n",
    "print(\"Recall  :\", rec)\n",
    "print(\"AUC/ROC :\", auc)\n",
    "print(\"Waktu training :\", train_time)\n",
    "print(\"Waktu testing  :\", test_time)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
